{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input, Dropout, Convolution2D, MaxPooling2D, Flatten\n",
    "from keras.utils import np_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PICTURE_SIZE = 64\n",
    "CHANNELS = 'rgb'\n",
    "\n",
    "INPUT_COLUMNS = []\n",
    "\n",
    "for color in CHANNELS:\n",
    "    INPUT_COLUMNS.extend(['%s%i' % (color, i)\n",
    "                          for i in range(PICTURE_SIZE ** 2)])\n",
    "old_column=list(range(0,12288))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def load_images(path):\n",
    "    img_data = []\n",
    "    labels = []\n",
    "    idx_to_label = []\n",
    "    i = -1\n",
    "    for fruit in os.listdir(path):\n",
    "        fruit_path = os.path.join(path,fruit)\n",
    "        labels.append(fruit)\n",
    "        i = i+1\n",
    "        for img in os.listdir(fruit_path):\n",
    "            img_path = os.path.join(fruit_path,img)\n",
    "            image = cv2.imread(img_path)\n",
    "            image = cv2.resize(image, (64, 64))\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            img_data.append(image)\n",
    "            idx_to_label.append(i)\n",
    "    return np.array(img_data),np.array(idx_to_label),labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_path = '/home/fede/Documentos/Machine-learning/PT-1/data/Training'\n",
    "validation_data_path = '/home/fede/Documentos/Machine-learning/PT-1/data/Validation'\n",
    "X_train,y_train,label_data = load_images(training_data_path)\n",
    "X_test,y_test,label_data_garbage = load_images(validation_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rearmado=X_train.reshape(len(y_train),-1)#Rearma el array en dos dimensiones \n",
    "\n",
    "trainDF=pd.DataFrame(data=train_rearmado) \n",
    "\n",
    "etiqueta=pd.Series(data=y_train) #crea una serie con el index de las imagenes y el index de las etiquetas\n",
    "\n",
    "etiqueta=etiqueta.replace({v: k for v, k in enumerate(label_data)},)#remplaza el index de las etiquetas con nombre de las mismas\n",
    "\n",
    "\n",
    "trainDF['etiqueta']=etiqueta\n",
    "print(trainDF.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rearmado=X_test.reshape(len(y_test),12288)#Rearma el array en dos dimensiones \n",
    "\n",
    "testDF=pd.DataFrame(data=test_rearmado) \n",
    "\n",
    "etiqueta=pd.Series(data=y_test) #crea una serie con el index de las imagenes y el index de las etiquetas\n",
    "\n",
    "etiqueta=etiqueta.replace({v: k for v, k in enumerate(label_data)},)#remplaza el index de las etiquetas con nombre de las mismas\n",
    "\n",
    "\n",
    "testDF['etiqueta']=etiqueta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(samples):\n",
    "    for index, sample in samples.iterrows():\n",
    "\n",
    "        sample_as_grid = sample[old_column].values.reshape(len(CHANNELS), PICTURE_SIZE, PICTURE_SIZE).astype(np.float)\n",
    "        sample_as_grid = np.transpose(sample_as_grid, (1, 2, 0)) / 255\n",
    "        \n",
    "        plt.axis('off')\n",
    "        plt.imshow(sample_as_grid, interpolation='nearest')\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "testDF.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(trainDF.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = trainDF.copy()\n",
    "test = testDF.copy()\n",
    "\n",
    "sets = (\n",
    "    ('train', train),\n",
    "    ('test', test),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_inputs(dataset):\n",
    "    \"\"\"\n",
    "    Extrae del conjunto de datos original solo las \n",
    "    columnas que se deben utilizar como entrada. \n",
    "    \"\"\"\n",
    "    # estandarización rápida y simple: dividir todo por 255 :)\n",
    "    #return dataset[INPUT_COLUMNS].values / 255\n",
    "    return dataset[old_column].values.reshape(len(dataset), PICTURE_SIZE, PICTURE_SIZE, len(CHANNELS)) / 255\n",
    "\n",
    "\n",
    "def extract_outputs(dataset):\n",
    "    \"\"\"\n",
    "    Extrae del conjunto de datos original solo la \n",
    "    columna que se debe utilizar como salida y retorna\n",
    "    tantas columnas como etiquetas distintas existan.\n",
    "    Por ejemplo, podríamos pensar que las columnas resultantes\n",
    "    serían: es_fisa, es_gabi, es_mariano.\n",
    "    \"\"\"\n",
    "    is_fruit_columns = [(dataset.etiqueta == fruit).values for fruit in label_data]\n",
    "    return np.array(is_fruit_columns).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    #Dense(10, activation='tanh', input_shape=(len(INPUT_COLUMNS), )),\n",
    "    Convolution2D(8, (4, 4), activation='relu', input_shape=(PICTURE_SIZE, PICTURE_SIZE, len(CHANNELS)),),\n",
    "    Convolution2D(8, (4, 4), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(4, 4)),\n",
    "    Dropout(0.2),\n",
    "    Flatten(),\n",
    "        \n",
    "    Dense(10, activation='tanh'),\n",
    "    Dropout(0.2),\n",
    "    Dense(10, activation='tanh'),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    Dense(len(label_data), activation='softmax'),\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy',],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    extract_inputs(train), \n",
    "    extract_outputs(train), \n",
    "    epochs=5,\n",
    "    batch_size=128,\n",
    "    validation_data=(\n",
    "        extract_inputs(test),\n",
    "        extract_outputs(test),\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
